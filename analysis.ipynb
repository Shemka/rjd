{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "ROOT_DIR = os.path.dirname(os.path.abspath('plots'))\n",
    "DIR_PLOTS = ROOT_DIR + '/plots/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV NAMES\n",
    "names = 'январь февраль март апрель май июнь июль август сентябрь октябрь ноябрь'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'processed/\\xd0\\xb0\\xd0\\xb2\\xd0\\xb3\\xd1\\x83\\xd1\\x81\\xd1\\x82.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7bea5949be69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'processed/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2batch2df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'processed/\\xd0\\xb0\\xd0\\xb2\\xd0\\xb3\\xd1\\x83\\xd1\\x81\\xd1\\x82.csv' does not exist"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for name in names:\n",
    "    df = pd.read_csv('processed/'+str(name)+'.csv', sep=';', header=None).iloc[:, :-2]\n",
    "    dfs.append(df2batch2df(process_df(df)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Little process\n",
    "def process_df(df):\n",
    "    df.columns = ['m', 'otst', 'st', 'deviation', 'len']\n",
    "    df = df.sort_values(by='m').reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# df2batch2df function !!!U DO NOT NEED THIS!!!\n",
    "# Convert None to lowest possible number or leave number if there it is\n",
    "def nn(n):\n",
    "    return -1 if n is None else n\n",
    "\n",
    "# Export 100m batches and convert it into DF\n",
    "# GO DOWN\n",
    "def df2batch2df(df):\n",
    "    ush = None\n",
    "    p = None\n",
    "    prp = None\n",
    "    prl = None\n",
    "    r = None\n",
    "    rows = []\n",
    "    from_ = df['m'][0] - (df['m'][0] % 100)\n",
    "    to = from_ + 100\n",
    "    \n",
    "    for j, i in enumerate(df['m']):\n",
    "        \n",
    "        if i >= to:\n",
    "            from_ += 100\n",
    "            to += 100\n",
    "            rows.append([len(rows), ush, p, prp, prl, r])\n",
    "            ush = None\n",
    "            p = None\n",
    "            prp = None\n",
    "            prl = None\n",
    "            r = None\n",
    "\n",
    "        if df.loc[j]['otst'] == 'Уш':\n",
    "            ush = max([nn(ush), df.iloc[j]['deviation']])\n",
    "\n",
    "        elif df.loc[j]['otst'] == 'П':\n",
    "            p = max([nn(p), df.iloc[j]['deviation']])\n",
    "\n",
    "        elif df.loc[j]['otst'] == 'Пр.п':\n",
    "            prp = max([nn(prp), df.iloc[j]['deviation']])\n",
    "\n",
    "        elif df.loc[j]['otst'] == 'Пр.л':\n",
    "            prl = max([nn(prl), df.iloc[j]['deviation']])\n",
    "\n",
    "        elif df.loc[j]['otst'] == 'Р':\n",
    "            r = max([nn(p), df.iloc[j]['deviation']])\n",
    "\n",
    "    rows.append([len(rows), ush, p, prp, prl, r])\n",
    "\n",
    "    return pd.DataFrame(rows, columns=['id', 'уш', 'п', 'пр.п', 'пр.л', 'р'])\n",
    "\n",
    "# Return False if x is not None or np.nan\n",
    "def condition(x):\n",
    "    if x is None:\n",
    "        return False\n",
    "    else:\n",
    "        return not math.isnan(x)\n",
    "\n",
    "# Calculate intersection with critical maximum/minimum\n",
    "def inters(coefs, brd):\n",
    "    x = (brd - coefs[1])/coefs[0]\n",
    "    return x\n",
    "\n",
    "# Plot approximated trend and save its plot into an image format\n",
    "def plot_approx(id, col_n, dfs, save=False):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Collect Data\n",
    "    x = [i for i in range(len(dfs))]\n",
    "    y = []\n",
    "    for i in x:\n",
    "        val = dfs[i].values[id][col_n]\n",
    "        y.append(val)\n",
    "    x = list(filter(lambda x: condition(y[x]), x))\n",
    "    y = list(filter(lambda x: condition(x), y))\n",
    "    \n",
    "    # Fit model\n",
    "    clf = LinearRegression()\n",
    "    clf.fit(np.array(x).reshape(-1, 1), y)\n",
    "    cf = [clf.coef_[0], clf.intercept_]\n",
    "    \n",
    "    # Specify borders\n",
    "    if col_n == 1:\n",
    "        y_border = 1548\n",
    "        brd_dwn = 1512\n",
    "    elif col_n == 2:\n",
    "        y_border = 50\n",
    "        brd_dwn = 0\n",
    "    elif col_n in [3, 4]:\n",
    "        y_border = 45\n",
    "        brd_dwn = 0\n",
    "        \n",
    "    x_u = inters(cf, y_border)\n",
    "    x_d = inters(cf, brd_dwn)\n",
    "    nx = max(x_u, x_d)\n",
    "    ny = y_border if nx == x_u else brd_dwn\n",
    "    \n",
    "    plt.plot(x+[nx+10], [y_border for _ in x+[nx]], 'b--', label='Максимум/минимум')\n",
    "    plt.plot(x+[nx+10], [brd_dwn for _ in x+[nx]], 'b--')\n",
    "    plt.plot(x, clf.predict(np.array(x).reshape(-1,1)), 'g-', label='тренд')\n",
    "    plt.plot([x[-1]]+[nx], [clf.predict(np.array(x).reshape(-1, 1))[-1]]+[ny], 'g--', label='предсказанный тренд')\n",
    "    plt.scatter(x, y, label='измерения')\n",
    "    plt.scatter([nx], [ny], label='критическая точка ~'+str(int(nx))+'\\nмесяц с начала отсчета')\n",
    "    plt.xlabel('ID месяца')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot saving\n",
    "    if save:\n",
    "        plt.savefig(save)\n",
    "\n",
    "# Looking for closest \"die date\" for exact 100-meter\n",
    "# Can save \n",
    "def closest_die_date(id, dfs, start_year=2019, start_month=2, img=True):\n",
    "    mx = 999999999999\n",
    "    с = 0\n",
    "    for i in range(1, 5):\n",
    "        x = [i for i in range(len(dfs))]\n",
    "        y = []\n",
    "        for j in x:\n",
    "            val = dfs[j].values[id][i]\n",
    "            y.append(val)\n",
    "            \n",
    "        x = list(filter(lambda x: condition(y[x]), x))\n",
    "        y = list(filter(lambda x: condition(x), y))\n",
    "\n",
    "        # Fit model\n",
    "        clf = LinearRegression()\n",
    "        try:\n",
    "            clf.fit(np.array(x).reshape(-1, 1), y)\n",
    "        except:\n",
    "            continue\n",
    "        cf = [clf.coef_[0], clf.intercept_]\n",
    "\n",
    "        # Specify borders\n",
    "        if i == 1:\n",
    "            y_border = 1548\n",
    "            brd_dwn = 1512\n",
    "\n",
    "        elif i == 2:\n",
    "            y_border = 50\n",
    "            brd_dwn = 0\n",
    "\n",
    "        elif i in [3, 4]:\n",
    "            y_border = 45\n",
    "            brd_dwn = 0\n",
    "\n",
    "        x_u = inters(cf, y_border)\n",
    "        x_d = inters(cf, brd_dwn)\n",
    "        nx = max(x_u, x_d)\n",
    "        ny = y_border if nx == x_u else brd_dwn\n",
    "        if ny == brd_dwn and i in [2, 3, 4]:\n",
    "            continue\n",
    "        mx = min(mx, nx)\n",
    "        if mx == nx:\n",
    "            c = i\n",
    "    \n",
    "    if img:\n",
    "        cols = list(dfs[0].columns)\n",
    "        plot_approx(id, c, dfs, str(start_year)+'-'+str(start_month)+'/plots/'+cols[i]+str(id)+'.jpg')\n",
    "    return int(mx), str(start_year)+'-'+str(start_month)+'/plots/'+cols[i]+str(id)+'.jpg'\n",
    "\n",
    "# Batches counter\n",
    "def min_ids(dfs):\n",
    "    mn = 11\n",
    "    for i in range(len(dfs)):\n",
    "        mn = min(dfs[i].shape[0], mn)\n",
    "    return mn\n",
    "\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# !!!!!!!!! YOU NEED ONLY THIS ONE !!!!!!!!!!!!!!!!!!!!!!\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# It is return PATH to excel file\n",
    "def problems_to_excel(dfs, start_year=2019, start_month=2):\n",
    "    rows = []\n",
    "    \n",
    "    for i in range(min_ids(dfs)):\n",
    "        m, path = closest_die_date(i, dfs, start_year, start_month)\n",
    "        rows.append([str(i*100)+'-'+str((i+1)*100)+'м', str(start_month+m%12)+'-'+str(start_year+m//12)])\n",
    "    pd.DataFrame(rows, columns=['промежуток', 'критическая_дата']).to_excel('critical-from-'+str(start_year)+'-'+str(start_month)+'.xlsx')\n",
    "    return os.path.join(ROOT_DIR, 'critical-from-'+str(start_year)+'-'+str(start_month)+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
